# -*- coding: utf-8 -*-
"""Task 1 complete

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lcVumGj4MaZTABvmwJYDAqPTn1-DvuHm
"""

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# Load and preprocess MNIST dataset
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0

# Define the teacher model
def build_teacher_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2), strides=(1, 1)),
        layers.Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),
        layers.MaxPooling2D((2, 2), strides=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(10, activation='softmax')
    ])
    return model

# Define the student model
def build_student_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2), strides=(1, 1)),
        layers.Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),
        layers.MaxPooling2D((2, 2), strides=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(10)
    ])
    return model

# Define loss functions
def compute_teacher_loss(y_true, y_pred):
    return tf.keras.losses.categorical_crossentropy(y_true, y_pred)

def compute_student_loss(y_true, y_pred, alpha=0.5, temperature=1.0):
    soft_student = tf.nn.softmax(y_pred / temperature)
    soft_teacher = tf.nn.softmax(y_true / temperature)
    return alpha * tf.keras.losses.categorical_crossentropy(soft_teacher, soft_student) + (1 - alpha) * tf.keras.losses.categorical_crossentropy(y_true, y_pred)

# Function to train and evaluate a model
def train_and_evaluate(model, train_images, train_labels, test_images, test_labels, num_epochs=12, alpha=0.5, temperature=1.0, model_name=None):
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss=lambda y_true, y_pred: compute_student_loss(y_true, y_pred, alpha, temperature),
                  metrics=['accuracy'])

    history = model.fit(train_images, train_labels, epochs=num_epochs, validation_data=(test_images, test_labels))
    test_loss, test_accuracy = model.evaluate(test_images, test_labels)

    if model_name:
        model.save(model_name)  # Save the model if a model name is provided

    return test_accuracy

# Build teacher and student models
teacher_model = build_teacher_model()
student_model = build_student_model()

# Train and evaluate teacher model and save it
teacher_accuracy = train_and_evaluate(teacher_model, train_images, tf.keras.utils.to_categorical(train_labels), test_images, tf.keras.utils.to_categorical(test_labels), model_name="teacher_model.h5")

# Define a range of temperature values
temperatures = [1, 2, 4, 16, 32, 64]

# List to store student test accuracies
student_accuracies = []

for temperature in temperatures:
    # Train and evaluate student model and save it with a temperature-specific name
    student_model_name = f"student_model_T{temperature}.h5"
    student_accuracy = train_and_evaluate(student_model, train_images, tf.keras.utils.to_categorical(train_labels), test_images, tf.keras.utils.to_categorical(test_labels), temperature=temperature, model_name=student_model_name)
    student_accuracies.append(student_accuracy)

# Plot the student test accuracies vs. temperature
plt.figure(figsize=(8, 6))
plt.plot(temperatures, student_accuracies, marker='o', linestyle='-')
plt.xlabel('Temperature (T)')
plt.ylabel('Student Test Accuracy')
plt.title('Student Test Accuracy vs. Temperature')
plt.grid(True)
plt.show()

print("Teacher Model Test Accuracy:", teacher_accuracy)
print("Student Model Test Accuracies:", student_accuracies)

def build_student_model():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)),
        layers.MaxPooling2D((2, 2), strides=(1, 1)),
        layers.Conv2D(64, (3, 3), strides=(1, 1), activation='relu'),
        layers.MaxPooling2D((2, 2), strides=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(10, activation='softmax')
    ])
    return model

# Build and compile the student model
student_model = build_student_model()
student_model.compile(optimizer=Adam(learning_rate=0.001),
                      loss='categorical_crossentropy',  # Use plain cross-entropy loss
                      metrics=['accuracy'])

def train_and_evaluate_without_kd(model, train_images, train_labels, test_images, test_labels, num_epochs=12, model_name=None):
    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='categorical_crossentropy',  # Use plain cross-entropy loss
                  metrics=['accuracy'])

    history = model.fit(train_images, train_labels, epochs=num_epochs, validation_data=(test_images, test_labels))
    test_loss, test_accuracy = model.evaluate(test_images, test_labels)

    if model_name:
        model.save(model_name)  # Save the model if a model name is provided

    return test_accuracy

# Train and evaluate the student model without KD
student_model_name = "student_model_without_kd.h5"
student_accuracy = train_and_evaluate_without_kd(student_model, train_images, tf.keras.utils.to_categorical(train_labels), test_images, tf.keras.utils.to_categorical(test_labels), model_name=student_model_name)

print("Student Model (Without KD) Test Accuracy:", student_accuracy)
